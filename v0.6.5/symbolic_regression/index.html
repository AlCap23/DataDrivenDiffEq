<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Symbolic Regression · DataDrivenDiffEq.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://datadriven.sciml.ai/stable/symbolic_regression/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">DataDrivenDiffEq.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../quickstart/">Getting Started</a></li><li><a class="tocitem" href="../prob_and_solve/">Problems And Solution</a></li><li><a class="tocitem" href="../basis/">Basis</a></li><li><a class="tocitem" href="../koopman/">Koopman</a></li><li><a class="tocitem" href="../optimization/">Sparse Optimization</a></li><li class="is-active"><a class="tocitem" href>Symbolic Regression</a><ul class="internal"><li><a class="tocitem" href="#SymbolicRegression"><span>SymbolicRegression</span></a></li><li><a class="tocitem" href="#OccamNet"><span>OccamNet</span></a></li></ul></li><li><a class="tocitem" href="../utils/">Utilities</a></li><li><a class="tocitem" href="../contributions/">Contributing</a></li><li><a class="tocitem" href="../citations/">Citing</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Symbolic Regression</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Symbolic Regression</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SciML/DataDrivenDiffEq.jl/blob/master/docs/src/symbolic_regression.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Symbolic-Regression"><a class="docs-heading-anchor" href="#Symbolic-Regression">Symbolic Regression</a><a id="Symbolic-Regression-1"></a><a class="docs-heading-anchor-permalink" href="#Symbolic-Regression" title="Permalink"></a></h1><p>Using <a href="@ref sparse_optimization">sparse regression</a> limits the discovery to a generalized linear model where it is assumed that the nonlinear <a href="@ref">basis</a> can capture the underlying function properly. Another approach is to use a general expression tree, which commonly encodes the function to discover as a binary tree where the nodes represent unary or binary operators acting on their children. <code>DataDrivenDiffEq</code> includes the following symbolic regression algorithms.</p><h2 id="SymbolicRegression"><a class="docs-heading-anchor" href="#SymbolicRegression">SymbolicRegression</a><a id="SymbolicRegression-1"></a><a class="docs-heading-anchor-permalink" href="#SymbolicRegression" title="Permalink"></a></h2><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>This feature requires the explicit loading of <a href="https://github.com/MilesCranmer/SymbolicRegression.jl">SymbolicRegression.jl</a> in addition to <code>DataDrivenDiffEq</code>. It will <em>only</em> be useable if loaded like:</p><pre><code class="language-julia hljs">using DataDrivenDiffEq
using SymbolicRegression</code></pre></div></div><p><code>DataDrivenDiffEq</code> provides an interface to <a href="https://github.com/MilesCranmer/SymbolicRegression.jl">SymbolicRegression.jl</a> to <code>solve</code> a <a href="@ref">DataDrivenProblem</a>:</p><pre><code class="language-julia hljs">using DataDrivenDiffEq
using LinearAlgebra
using Random
using SymbolicRegression


Random.seed!(1223)
# Generate a multivariate function for SymbolicRegression
X = rand(2,20)
f(x) = [sin(x[1]); exp(x[2])]
Y = hcat(map(f, eachcol(X))...)

# Define the options
opts = EQSearch([+, *, sin, exp], maxdepth = 1, progress = false, verbosity = 0)

# Define the problem
prob = DirectDataDrivenProblem(X, Y)

# Solve the problem
res = solve(prob, opts, numprocs = 0, multithreading = false)
sys = result(res)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Model ##Basis#81188 with 2 equations
States : x[1] x[2]
Independent variable: t
Equations
φ₁ = sin(x[1])
φ₂ = exp(x[2])</code></pre><p>Where <code>solve</code> is used with <a href="#DataDrivenDiffEq.EQSearch"><code>EQSearch</code></a>, which wraps <a href="https://astroautomata.com/SymbolicRegression.jl/stable/api/#Options"><code>Options</code></a> provided by <a href="https://github.com/MilesCranmer/SymbolicRegression.jl">SymbolicRegression.jl</a>. Additional keyworded arguments are <code>max_iter = 10</code>, which defines the number of iterations, <code>weights</code> which weight the measurements of the dependent variable (e.g. <code>X</code>, <code>DX</code> or <code>Y</code> depending on the <a href="@ref">DataDrivenProblem</a>), <code>numprocs</code> which indicates the number of processes to use, <code>procs</code> for use with manually setup processes, <code>multithreading = false</code> for multithreading and <code>runtests = true</code> which performs initial testing on the environment to check for possible errors. It mimics the behaviour of <a href="https://astroautomata.com/SymbolicRegression.jl/stable/api/#EquationSearch"><code>EquationSearch</code></a>.</p><h3 id="Related-Types"><a class="docs-heading-anchor" href="#Related-Types">Related Types</a><a id="Related-Types-1"></a><a class="docs-heading-anchor-permalink" href="#Related-Types" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="DataDrivenDiffEq.EQSearch" href="#DataDrivenDiffEq.EQSearch"><code>DataDrivenDiffEq.EQSearch</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">struct EQSearch &lt;: DataDrivenDiffEq.AbstractSymbolicRegression</code></pre><p>Options for using SymbolicRegression.jl within the <code>solve</code> function. Automatically creates <a href="https://astroautomata.com/SymbolicRegression.jl/stable/api/#Options"><code>Options</code></a> with the given specification. Sorts the operators stored in <code>functions</code> into unary and binary operators on conversion.</p><p><strong>Fields</strong></p><ul><li><p><code>functions</code></p><p>Operators used for symbolic regression</p></li><li><p><code>kwargs</code></p><p>Additionally keyworded arguments passed to SymbolicRegression.Options</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DataDrivenDiffEq.jl/blob/95b5619c31476ddb434bcf3c3533d78175f4fbe4/src/symbolic_regression/symbolic_regression.jl#L5">source</a></section></article><h2 id="OccamNet"><a class="docs-heading-anchor" href="#OccamNet">OccamNet</a><a id="OccamNet-1"></a><a class="docs-heading-anchor-permalink" href="#OccamNet" title="Permalink"></a></h2><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>This feature requires the explicit loading of <a href="https://fluxml.ai/">Flux.jl</a> in addition to <code>DataDrivenDiffEq</code>. It will <em>only</em> be useable if loaded like:</p><pre><code class="language-julia hljs">using DataDrivenDiffEq
using Flux</code></pre></div></div><p>As introduced in <a href="https://arxiv.org/abs/2007.10784">Interpretable Neuroevolutionary Models for Learning Non-Differentiable Functions and Programs </a>, <code>OccamNet</code> is a special form of symbolic regression which uses a probabilistic approach to equation discovery by using a feedforward multilayer neural network. In contrast to normal architectures, each layer&#39;s weights reflect the probability of which inputs to use. Additionally a set of activation functions is used, instead of a single function. Similar to simulated annealing, a temperature is included to control the exploration of possible functions.</p><p><code>DataDrivenDiffEq</code> offers two main interfaces to <code>OccamNet</code>: a <code>Flux</code> based API with <code>Flux.train!</code> and a <code>solve(...)</code> function.</p><p>Consider the following example, where we want to discover a vector valued function:</p><pre><code class="language-julia hljs">using DataDrivenDiffEq
using LinearAlgebra
using ModelingToolkit
using Flux
using Random

# Due to random values
Random.seed!(1223)

# Generate a multivariate dataset
X = rand(2,10)
f(x) = [sin(π*x[2]+x[1]); exp(x[2])]
Y = hcat(map(f, eachcol(X))...)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×10 Matrix{Float64}:
 0.730729  0.999265  0.969019  0.625678  …  0.669184  0.95687  0.92499
 1.04471   1.29513   1.69627   1.74007      1.5878    1.36212  1.20932</code></pre><p>Next, we define our network:</p><pre><code class="language-julia hljs">net = OccamNet(2, 2, 3, Function[sin, +, *, exp], skip = true, constants = Float64[π])</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">OccamNet(4, Constants 1, Parameters 0)</code></pre><p>Where <code>2,2,3</code> refers to input and output dimension and the number of layers <em>without the output layer</em>. We also define that each layer uses the functions <code>sin, +, *, exp</code> as activations and uses a <code>π</code> as a constant, which get concatenated to the input data. Additionally, <code>skip</code> indicates the useage of skip connections, which allow the output of each layer to be passed onto the output layer directly.</p><p>To train the network over <code>100</code> epochs using <code>ADAM</code>, we type</p><pre><code class="language-julia hljs">Flux.train!(net, X, Y, ADAM(1e-2), 100, routes = 100, nbest = 3)</code></pre><p>Under the hood, we select possible routes, <code>routes</code>, through the network based on the probability reflected by the <a href="#DataDrivenDiffEq.ProbabilityLayer"><code>ProbabilityLayer</code></a> forming the network. From these we take the <code>nbest</code> candidates to train the parameters of the network, meaning increase the probability of those routes.</p><p>Lets have a look at some possible equations after the initial training. We can use <code>rand</code> to sample a route through the network, compute the output probability with <code>probability</code> and transform it into analytical equations by simply using <code>ModelingToolkit</code>s variables as input. The call <code>net(x, route)</code> uses the route to compute just the element on this path.</p><pre><code class="language-julia hljs">@variables x[1:2]

for i in 1:10
  route = rand(net)
  prob = probability(net, route)
  eq = simplify.(net(x, route))
  print(eq , &quot; with probability &quot;,  prob, &quot;\n&quot;)
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Symbolics.Num[sin(exp(x[2])), exp(x[2]) + x[2]] with probability [0.02874208875253813, 0.001020356452889173]
Symbolics.Num[sin(x[1]*(3.141592653589793 + x[1])), exp(x[2])] with probability [2.4268035492071496e-5, 0.10004718259206825]
Symbolics.Num[exp(x[2]), exp(x[2])] with probability [0.010309792918739237, 0.011230891123571646]
Symbolics.Num[x[1], 3.141592653589793 + x[1]] with probability [0.05388524671461696, 0.0011426040901520863]
Symbolics.Num[-0.9125775986692777, exp(x[2])] with probability [0.006522697942050591, 0.02707702334938692]
Symbolics.Num[19333.689074365135, exp(x[2])] with probability [0.0006005975724607248, 0.10004718259206825]
Symbolics.Num[sin(exp(x[2])), x[1]] with probability [0.047892106785117454, 0.04565968696366679]
Symbolics.Num[sin(exp(x[2])), exp(x[2])] with probability [0.047892106785117454, 0.10004718259206825]
Symbolics.Num[1.2246467991473532e-16, exp(x[2])] with probability [0.017199511543924042, 0.02707702334938692]
Symbolics.Num[exp(x[2]^2), x[2]^2] with probability [0.0015392645555503143, 0.00936874746648553]</code></pre><p>We see the networks proposals are not very certain. Hence, we will train for some more epochs and look at the output again.</p><pre><code class="language-julia hljs">Flux.train!(net, X, Y, ADAM(1e-2), 900, routes = 100, nbest = 3)

for i in 1:10
  route = rand(net)
  prob = probability(net, route)
  eq = simplify.(net(x, route))
  print(eq , &quot; with probability &quot;,  prob, &quot;\n&quot;)
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Symbolics.Num[sin(x[1] + 3.141592653589793x[2]), exp(x[2])] with probability [0.8965549834356896, 0.956500412755264]
Symbolics.Num[sin(x[1] + 3.141592653589793x[2]), exp(x[2])] with probability [0.8965549834356896, 0.956500412755264]
Symbolics.Num[sin(x[1] + 3.141592653589793x[2]), exp(x[2])] with probability [0.8965549834356896, 0.956500412755264]
Symbolics.Num[sin(x[1] + 3.141592653589793x[2]), exp(x[2])] with probability [0.8965549834356896, 0.956500412755264]
Symbolics.Num[sin(x[1] + 3.141592653589793x[2]), exp(x[2])] with probability [0.8965549834356896, 0.956500412755264]
Symbolics.Num[sin(x[1] + 3.141592653589793x[2]), exp(x[2])] with probability [0.8965549834356896, 0.956500412755264]
Symbolics.Num[sin(x[1] + 3.141592653589793x[2]), exp(x[2])] with probability [0.8965549834356896, 0.956500412755264]
Symbolics.Num[sin(exp(x[2])), exp(x[2])] with probability [0.002425719500856979, 0.956500412755264]
Symbolics.Num[sin(x[1] + 3.141592653589793x[2]), exp(x[2])] with probability [0.8965549834356896, 0.956500412755264]
Symbolics.Num[sin(x[1] + 3.141592653589793x[2]), exp(x[2])] with probability [0.8965549834356896, 0.956500412755264]</code></pre><p>The network is quite certain about the equation now, which is in fact our unknown mapping. To extract the solution with the highest probability, we set the temperature of the underlying distribution to a very low value. In the limit of <code>t ↦ 0</code> we approach a Dirac distribution, hence extracting the most likely terms.</p><pre><code class="language-julia hljs">set_temp!(net, 0.01)
route = rand(net)
prob = probability(net, route)
eq = simplify.(net(x, route))
print(eq , &quot; with probability &quot;,  prob, &quot;\n&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Symbolics.Num[sin(x[1] + 3.141592653589793x[2]), exp(x[2])] with probability [1.0, 1.0]</code></pre><p>The same procedure is automated in the <code>solve</code> function. Using the same data, we wrap the algorithms information in the <a href="#DataDrivenDiffEq.OccamSR"><code>OccamSR</code></a> struct and define a <a href="../prob_and_solve/#DataDrivenDiffEq.DataDrivenProblem"><code>DataDrivenProblem</code></a>:</p><pre><code class="language-julia hljs"># Define the problem
ddprob = DirectDataDrivenProblem(X, Y)
# Define the algorithm
sr_alg = OccamSR(functions = Function[sin, +, *, exp], skip = true, layers = 3, constants = [π])
# Solve the problem
res = solve(ddprob, sr_alg, ADAM(1e-2), max_iter = 1000, routes = 100, nbest = 3)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Explicit Result
Solution with 2 equations and 0 parameters.
Returncode: sucess
L2 Norm Error: 0.0
AICC: Inf</code></pre><p>Within <code>solve</code> the network is generated using the information provided by the <a href="@ref">DataDrivenProblem</a> in form of states, control and independent variables as well as the specified options, followed by training the network and extracting the equation with the highest probability by setting the temperature as above. After computing additional metrics, a <a href="@ref">DataDrivenSolution</a> is returned where the equations are transformed  into a <a href="../basis/#DataDrivenDiffEq.Basis"><code>Basis</code></a> useable with <code>ModelingToolkit</code>.</p><p>The metrics can be accessed via:</p><pre><code class="language-julia hljs">metrics(res)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(Probability = 0.8425497124024455, Error = 0.0, AICC = Inf, Probabilities = [0.898724142309076, 0.9374953589626484], Errors = [0.0, 0.0], AICCs = [Inf, Inf])</code></pre><p>and the resulting <a href="../basis/#DataDrivenDiffEq.Basis"><code>Basis</code></a> by:</p><pre><code class="language-julia hljs">result(res)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Model ##Basis#81191 with 2 equations
States : x[1] x[2]
Independent variable: t
Equations
Differential(t)(x[1]) = sin(x[1] + 3.141592653589793x[2])
Differential(t)(x[2]) = exp(x[2])</code></pre><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>Right now, the resulting basis is not using parameters, but raw numerical values.</p></div></div><h3 id="Related-Types-2"><a class="docs-heading-anchor" href="#Related-Types-2">Related Types</a><a class="docs-heading-anchor-permalink" href="#Related-Types-2" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="DataDrivenDiffEq.OccamNet" href="#DataDrivenDiffEq.OccamNet"><code>DataDrivenDiffEq.OccamNet</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct OccamNet{F, C, P} &lt;: DataDrivenDiffEq.AbstractOccam</code></pre><p>Defines an <code>OccamNet</code> which learns symbolic expressions from data using a probabilistic approach. See <a href="https://arxiv.org/abs/2007.10784">Interpretable Neuroevolutionary Models for Learning Non-Differentiable Functions and Programs </a> for more details.</p><p>It get constructed via:</p><pre><code class="language-julia hljs">net = OccamNet(inp::Int, outp::Int, layers::Int, f::Vector{Function}, t::Real = 1.0; constants = typeof(t)[], parameters::Int = 0, skip::Bool = false, init_w = ones, init_p = Flux.glorot_uniform)</code></pre><p><code>inp</code> describes the size of the input domain, <code>outp</code> the size of the output domain, <code>layers</code> the number of layers (including the input layer and excluding the linear output layer) and <code>f</code> the functions to be used. Optional is the temperature <code>t</code> which is set to <code>1.0</code> at the beginning.</p><p>Keyworded arguments are <code>constants</code>, a vector of constants like π, ℯ which can concatenated to the input, the number of trainable <code>parameters</code> and if <code>skip</code> connections should be used. The constructors to the weights and parameters can be passed in via <code>init_w</code> and <code>init_p</code>.</p><p><code>OccamNet</code> is callable with and without a specific route, which can be sampled from the networks weights via <code>rand(net)</code>.</p><p><strong>Fields</strong></p><ul><li><p><code>c</code></p><p>The <code>Chain</code> representing the network</p></li><li><p><code>constants</code></p><p>Additional constants added to the input which are not trainable.</p></li><li><p><code>parameters</code></p><p>Additional parameters added to the input which are trainable.</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DataDrivenDiffEq.jl/blob/95b5619c31476ddb434bcf3c3533d78175f4fbe4/src/symbolic_regression/occamnet.jl#L167">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DataDrivenDiffEq.OccamSR" href="#DataDrivenDiffEq.OccamSR"><code>DataDrivenDiffEq.OccamSR</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">struct OccamSR{F, C, T} &lt;: DataDrivenDiffEq.AbstractSymbolicRegression</code></pre><p>Options for using OccamNet within the <code>solve</code> function. Automatically creates a network with the given specification.</p><p><strong>Fields</strong></p><ul><li><p><code>functions</code></p><p>Functions used within the network</p></li><li><p><code>constants</code></p><p>Constants added to the input</p></li><li><p><code>layers</code></p><p>Number of layers</p></li><li><p><code>parameters</code></p><p>Number of parameters</p></li><li><p><code>skip</code></p><p>Activate skip connections</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DataDrivenDiffEq.jl/blob/95b5619c31476ddb434bcf3c3533d78175f4fbe4/src/symbolic_regression/occamnet.jl#L331">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DataDrivenDiffEq.ProbabilityLayer" href="#DataDrivenDiffEq.ProbabilityLayer"><code>DataDrivenDiffEq.ProbabilityLayer</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">mutable struct ProbabilityLayer{F, W, T, A} &lt;: DataDrivenDiffEq.AbstractProbabilityLayer</code></pre><p>Defines a basic <code>ProbabilityLayer</code> in which the parameters act as probabilities via the <code>softmax</code> function for an array of functions.</p><p>The layer is callable either via <code>layer(x)</code>, using all weights to form the output or by <code>layer(x, route)</code> where route is the result of <code>rand(layer)</code> which samples the function arguments from the underlying distribution.</p><p><strong>Fields</strong></p><ul><li><p><code>op</code></p><p>Nonlinear functions forming the basis of the layer</p></li><li><p><code>weight</code></p><p>Weights</p></li><li><p><code>t</code></p><p>Temperature controlling the shape of the distribution</p></li><li><p><code>arieties</code></p><p>Arieties of the functions</p></li><li><p><code>skip</code></p><p>Skip connection</p></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DataDrivenDiffEq.jl/blob/95b5619c31476ddb434bcf3c3533d78175f4fbe4/src/symbolic_regression/occamnet.jl#L9">source</a></section></article><h3 id="Related-Functions"><a class="docs-heading-anchor" href="#Related-Functions">Related Functions</a><a id="Related-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Related-Functions" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-binding" id="DataDrivenDiffEq.set_temp!" href="#DataDrivenDiffEq.set_temp!"><code>DataDrivenDiffEq.set_temp!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">set_temp!(p, t)
</code></pre><p>Set the temperature of the <code>ProbabilityLayer</code> or <code>OccamNet</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DataDrivenDiffEq.jl/blob/95b5619c31476ddb434bcf3c3533d78175f4fbe4/src/symbolic_regression/occamnet.jl#L146">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DataDrivenDiffEq.probability" href="#DataDrivenDiffEq.probability"><code>DataDrivenDiffEq.probability</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">probability(o, route)
</code></pre><p>Returns the probability of the result of the <code>OccamNet</code> using the specific route.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DataDrivenDiffEq.jl/blob/95b5619c31476ddb434bcf3c3533d78175f4fbe4/src/symbolic_regression/occamnet.jl#L260">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DataDrivenDiffEq.logprobability" href="#DataDrivenDiffEq.logprobability"><code>DataDrivenDiffEq.logprobability</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">logprobability(o, route)
</code></pre><p>Returns the logprobability of the result of the <code>OccamNet</code> using the specific route.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DataDrivenDiffEq.jl/blob/95b5619c31476ddb434bcf3c3533d78175f4fbe4/src/symbolic_regression/occamnet.jl#L246">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DataDrivenDiffEq.probabilities" href="#DataDrivenDiffEq.probabilities"><code>DataDrivenDiffEq.probabilities</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">probabilities(p)
</code></pre><p>Return the probability associated with the <code>ProbabilityLayer</code> or <code>OccamNet</code> by applying <code>softmax</code> on the weights.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DataDrivenDiffEq.jl/blob/95b5619c31476ddb434bcf3c3533d78175f4fbe4/src/symbolic_regression/occamnet.jl#L94">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="DataDrivenDiffEq.logprobabilities" href="#DataDrivenDiffEq.logprobabilities"><code>DataDrivenDiffEq.logprobabilities</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">logprobabilities(p)
</code></pre><p>Return the logprobability associated with the <code>ProbabilityLayer</code> or <code>OccamNet</code> by applying <code>logsoftmax</code> on the weights.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/SciML/DataDrivenDiffEq.jl/blob/95b5619c31476ddb434bcf3c3533d78175f4fbe4/src/symbolic_regression/occamnet.jl#L106">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../optimization/">« Sparse Optimization</a><a class="docs-footer-nextpage" href="../utils/">Utilities »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.5 on <span class="colophon-date" title="Friday 6 August 2021 07:41">Friday 6 August 2021</span>. Using Julia version 1.6.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
